{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration Sentiment Analysis\n",
    "\n",
    "This notebook is for training purposes and as such has been simplified to highlight the core steps in training an ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load, Clean, Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('http://neueda.conygre.com/pydata/ml_fc/Restaurant_Reviews.tsv', sep='\\t')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - for simplicity this preparation function is greatly simplified. We could include further steps such as:\n",
    "* stemming / lemmatization\n",
    "* removing stop words\n",
    "* identification of the most symantically valuable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prepare_review(review):\n",
    "    \n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)    \n",
    "    return review.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not tasty and the texture was just nasty '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_review('Not tasty and the texture was just nasty.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow    loved this place ',\n",
       " 'crust is not good ',\n",
       " 'not tasty and the texture was just nasty ',\n",
       " 'stopped by during the late may bank holiday off rick steve recommendation and loved it ',\n",
       " 'the selection on the menu was great and so were the prices ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df['Review'].apply(prepare_review).tolist()\n",
    "\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This step is encoding the \"Bag of Words\" - the CountVectorizer utility does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split into independant and dependant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(corpus).toarray()  # Independent variables\n",
    "\n",
    "y = df['Liked'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split our data into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Choose and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are demonstrating inference / prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "\n",
      "Apologies\n"
     ]
    }
   ],
   "source": [
    "#new_review = \"Food was Great!\"\n",
    "#new_review = \"Service was awful, tasted revolting!\"\n",
    "#new_review = \"Could be better\"\n",
    "new_review = \"Food was not great\"\n",
    "\n",
    "prepared_review = prepare_review(new_review)\n",
    "\n",
    "feature_set = cv.transform( [prepared_review] )\n",
    "\n",
    "result = model.predict(feature_set.toarray())\n",
    "\n",
    "print(result)\n",
    "print()\n",
    "\n",
    "if result[0] == 1:\n",
    "    print('Glad you enjoyed your visit!')\n",
    "else:\n",
    "    print('Apologies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Validate / Measure the model\n",
    "\n",
    "In this case as this is a classification problem, we will use a confusion matrix. There are a number of further calculations we might do to extract more metrics from our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82 15]\n",
      " [20 83]]\n",
      "Accuracy:  0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cmatrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "print(cmatrix)\n",
    "\n",
    "print('Accuracy: ', (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reference, how do some other sklearn classification models perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = MultinomialNB()\n",
    "MNB_classifier.fit(X_train, y_train)\n",
    "cmatrix = confusion_matrix(y_test, MNB_classifier.predict(X_test))\n",
    "print(\"MNB_classifier accuracy:\", (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB_classifier accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "BNB_classifier = BernoulliNB()\n",
    "BNB_classifier.fit(X_train, y_train)\n",
    "cmatrix = confusion_matrix(y_test, BNB_classifier.predict(X_test))\n",
    "print(\"BNB_classifier accuracy:\", (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_classifier accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "LR_classifier = LogisticRegression()\n",
    "LR_classifier.fit(X_train, y_train)\n",
    "cmatrix = confusion_matrix(y_test, LR_classifier.predict(X_test))\n",
    "print(\"LR_classifier accuracy:\", (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_classifier accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "SGD_classifier = SGDClassifier()\n",
    "SGD_classifier.fit(X_train, y_train)\n",
    "cmatrix = confusion_matrix(y_test, SGD_classifier.predict(X_test))\n",
    "print(\"SGD_classifier accuracy:\", (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_classifier accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier = LinearSVC()\n",
    "SVC_classifier.fit(X_train, y_train)\n",
    "cmatrix = confusion_matrix(y_test, SVC_classifier.predict(X_test))\n",
    "print(\"SVC_classifier accuracy:\", (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_classifier accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_classifier = MLPClassifier(hidden_layer_sizes=(20), max_iter=1000)\n",
    "MLP_classifier.fit(X_train, y_train)\n",
    "\n",
    "cmatrix = confusion_matrix(y_test, MLP_classifier.predict(X_test))\n",
    "print(\"MLP_classifier accuracy:\", (cmatrix[0][0]  + cmatrix[1][1]) / cmatrix.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
